# Docker

**What is a Docker?**
- Docker is a containerization platform for developing, packaging, shipping, and running applications.
- It provides the ability to run an application in an isolated environment called a container.
- Makes deployment and development efficient.

**What is a Container?**
- A way to package an application with all the necessary dependencies and configuration.
- It can be easily shared
- Makes deployment and development efficient.

**Main Components of Docker**

- **Docker File:** It is a simple text file with instructions to build an image.
- **Docker Image:** Single File with all the dep and lib to run the
program.
- **Docker Containers:** Instance of an image.
- **Docker Registry:** A Docker registry is a central repository for storing and distributing Docker images.
    - **Registry**: A Docker Registry is a service that stores Docker images. It acts as a storage and distribution mechanism for Docker images. Developers can push (upload) and pull (download) Docker images to and from registries.
    - **Repository**: A Docker Repository is a collection of related Docker images, often with different versions of the same application or service. Within a Docker Registry, repositories organize images. Each repository can contain multiple image versions, identified by tags (e.g., `nginx:latest`, `nginx:1.19`, etc.).

The Docker Registry is where Docker images are physically stored. Docker Repositories organize related images within a registry, making it easier to manage and distribute different versions of applications or services.

### **Docker Engine Installation on Linux**

To install the Docker Engine on RedHat/CentOS, you can use the following commands:

Using CentOS repository, we can install Docker Engine on RedHat. First, we need to set up the repository.

**Set up the repository**

```
[root@redhat01 ~]# lscpu | more      # Check the architecture
[root@redhat01 ~]# sudo yum install -y yum-utils
[root@redhat01 ~]# sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
```

**Install Docker Engine**

To install the latest version, run:
```
[root@redhat01 ~]# sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
[root@redhat01 ~]# systemctl start docker.service
[root@redhat01 ~]# systemctl status docker.service
[root@redhat01 ~]# docker -v
[root@redhat01 ~]# docker ps
```

Install Docker Engine on other supported platforms: [Official Documentation](https://docs.docker.com/engine/install/)

### Creating DEMO Project - React Webpp

**Prerequisites:** <br>
Install Node.js and Visual Studio Code on your system. (Mac in this example)

Now open VS Code. Open the folder where you want to create this project and open the integrated terminal.
```
# node -v                           # Check Node.js version
v20.9.0
# npx create-react-app testapp      # Create a React-based application
Need to install the following packages:
create-react-app@5.0.1
Ok to proceed? (y)
```
This will create a new folder named testapp in your project directory, and all application files will be inside this testapp folder.

```
$ cd testapp        # Change directory to testapp
$ npm start         # Run the application
Compiled successfully!
You can now view testapp in the browser.

Local:              http://localhost:3000
On Your Network:    http://192.168.1.128:3000

Note that the development build is not optimized.
To create a production build, use npm run build.

webpack compiled successfully.
```
You can view the application in the browser using the link provided in the output. To **stop** the project, press `Ctrl+C`.

To run this application successfully, the app needs `node_modules` which will be saved in the **testapp** folder. If this folder is not available, you can run `npm install` to get these node modules and then run `npm start`.

Only main files are deployed while deploying the application; **node_modules** are not deployed. To obtain all the required node modules, use `npm install`, and then run it.

### Creating a Dockerfile

Create a new file named `Dockerfile` in testapp. You can also install the Docker extension in VS Code for easy Dockerfile creation.

```
FROM node:20

WORKDIR /myapp

COPY . .

RUN npm install

EXPOSE 3000

CMD ["npm", "start"]
```
**`FROM node:20`** : You need to specify a base for the image. Since this is a web app, you can use **node** as a base image. When you use `FROM node`, it retrieves the latest image from the Docker Registry. If you want to specify a particular version, you need to provide the tag name along with the image, such as `FROM node:20`. You can find available versions on the Docker repository.

**`WORKDIR /myapp`** : By default, when this Dockerfile creates a container from the image, it starts in an empty directory. You need to set a working directory where you want to run the application. This command creates a folder named **myapp** inside the container and sets it as the working directory.

**`COPY . .`** : Since this Dockerfile is in your local **testapp** folder, you need to copy all files from the current directory on your system to the container's working directory. Since you have set the working directory as **/myapp**, you can directly use `COPY . .`. Alternatively, you can specify the source directory explicitly: `COPY . /myapp`.

**`RUN npm install`** : To run the web app, the container needs the `node_modules` folder. After copying all main files to the working directory, you need to run `npm install` inside the container to install the required node modules.

**`EXPOSE 3000`** : Node.js applications typically listen on port 3000 by default. You can specify this port for the application to listen on by using the `EXPOSE` command in the Dockerfile.

**`CMD ["npm", "start"]`** : The Dockerfile is used to create an image, not to run the application directly. So you can't use `RUN npm start`. Therefore, you specify the command to start your application inside the container using `CMD`. In this example, it's `npm start`. Commands are passed in the form of arrays inside double quotes and separated by commas in the `CMD` instruction.

### Creating Docker Image

Go to the folder where your Dockerfile is present and run:
```
# docker build .
```
This will build an image using the instructions provided in the Dockerfile.

Once the image is created, you can check the image using:
```
# docker image ls
REPOSITORY TAG      IMAGE ID       CREATED          SIZE
<none>     <none>   2f02e42127df   36 seconds ago   1.39GB
```

### Run and Manage Docker containers

Using the image, you can create multiple containers.

To create containers, you need the IMAGE ID, which you will get from the previous command output.
```
# docker run 2f02e42127df
Compiled successfully!

You can now view testapp in the browser.

Local:              http://localhost:3000
On Your Network:    http://172.17.0.2:3000

Note that the development build is not optimized.
To create a production build, use npm run build.

webpack compiled successfully.
compiled successfully.
webpack compiled successfully.
```
The application is successfully running inside the container. You can see the output. However, this will continue running indefinitely because it's a web app and not a simple program that terminates after outputting.

But if you try to reach the website using `http://localhost:3000`, it will display **This site can't be reached**. This is because earlier, you could access this URL from your local system browser when the application was running on your local system. Now, it's running inside a container hosted on top of your local system. To make the URL accessible outside the container, you need to bind the port between the container and the local system.

In one terminal, the application is still running. First, stop this running application. You can open a different terminal window and run:
```
# docker ps           # process status
CONTAINER ID    IMAGE           COMMAND                     CREATED         PORTS   NAMES
b45c4f9544e8    2f02e42127df    "docker-entrypoint. s..."   2 minutes ago
0/tcp   dreamy_wiles
```

Whenever you run containers, by default, it assigns some random, unique names to them. You can stop the containers using this name. In our example, it's `dreamy_wiles`.

```
# docker stop dreamy_wiles
dreamy_wiles
# docker ps
CONTAINER   ID  IMAGE   COMMAND CREATED TS  NAMES
#
```
Now that the application is stopped, get the image ID and perform the port binding. The application listens on port 3000 inside the container, so bind it with port 3000 outside the container using the following command:
```
docker run -p <system_port>:<container_port> image_id
```
```
# docker image ls
REPOSITORY TAG      IMAGE ID       CREATED          SIZE
<none>     <none>   2f02e42127df   36 seconds ago   1.39GB
# docker run -p 3000:3000 2f02e42127df
```
Once you run the container using the above command, try accessing the URL from your local browser; you should now be able to access it.

### Running Container in Detached Mode

Now, whenever you run the container, you are running it in the foreground, which means you cannot easily perform other operations. We can run containers in the background and continue using our terminal for other tasks.

First, check the running containers and stop them.
```
# docker ps
CONTAINER ID    IMAGE           COMMAND                     CREATED         PORTS                    NAMES
b45c4f9544e8    2f02e42127df    "docker-entrypoint. s..."   15 minutes ago
0.0.0.0:3000->3000/tcp   nostalgic_dhawan
# docker stop nostalgic_dhawan
nostalgic_dhawan
```

To run containers in detached mode, use `-d` before `-p` for port binding in the `docker run` command.
```
# docker run -d -p 3000:3000 2f02e42127df
49acb5a75896e0d17e585d82f182f08c9df283e1b4304c837fa93a65e83d3d7b
#
```
This generates an ID, and the containers run in the background. The terminal is free for other commands. You can check whether your container is running using `docker ps`.

### Running Multiple Containers from a Single Image

Now, as the container is running in the background, if you try to use the same command again to create another container, it will give an error because port 3000 is already in use by another running application.
```
# docker run -d -p 3000:3000 2f0242127df
8388a5f0e0b7e858696a99cb0b5577230a12a3295ae7a546717755b4c8cd458
docker: Error response from daemon: driver failed programming external connectivity on endpoint awesome_pa
re (a31c43842eb68bbe069dd529d0554727fe9b2e2b6b1f0c3f86942d42b5d04): Bind for 0.0.0.0:3000 failed: port is already allocated.
```

You can use different ports for binding on your system. The container listens on port 3000 only, but you can bind it to different ports on your local system.
```
# docker run -d -p 3001:3000 2f02e42127df
bd2f1fe19f07efeef68164933436fc987280888f3bf78fe7a465f78d7366e680
# docker run -d -p 3002:3000 2f02e42127df
8efbb15678ea666fecf05645fa7ae13ac86924360aecf0fa8e3cab1f643d9732
# docker ps
CONTAINER ID    IMAGE           COMMAND                     CREATED         PORTS                    NAMES
8efbb15678ea    2f02e42127df    "docker-entrypoint. s..."   9 seconds ago
0.0.0.0:3002->3000/tcp   angry_ptolemy
bd2f1fe19f07    2f02e42127df    "docker-entrypoint. s..."   17 seconds ago
0.0.0.0:3001->3000/tcp   inspiring_wozniak
49acb5a75896    2f02e42127df    "docker-entrypoint. s..."   9 minutes ago
0.0.0.0:3000->3000/tcp   festive_colden
```
Since containers are isolated from each other, all three containers can listen on the same port simultaneously.

---